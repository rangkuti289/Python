# -*- coding: utf-8 -*-
"""CODIG.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BOK4pjeHJ03Rwty9ki-yuNGSB09P6-eY

# **Preparing**
"""

# Commented out IPython magic to ensure Python compatibility.
#menyiapkan library yang di perlukan
import itertools
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.ticker import NullFormatter
import pandas as pd
import numpy as np
import matplotlib.ticker as ticker
from sklearn import preprocessing
# %matplotlib inline

#menginput dataset yang di perlukan
from google.colab import files
uploaded = files.upload()

#menampilkan dataset
data = pd.read_csv('2010-2019.csv')
data

#colum yang berada pada data set
data.columns

#mengelompokan record
data['TEMP'][data['TEMP']<=70] = 70
data['TEMP'][(data['TEMP']>70) & (data['TEMP']<80) ] = 75
data['TEMP'][data['TEMP']>=80] = 80
data['TEMP'].value_counts()

"""# **CLEANING DATA**"""

#menghapus atribut yang tidak di gunakan
datafiltered = data.drop(['Unnamed: 0','STATION','NAME', 'TEMP_ATTRIBUTES', 'DEWP', 'DEWP_ATTRIBUTES', 'SLP','SLP_ATTRIBUTES', 'STP', 'STP_ATTRIBUTES', 'VISIB', 'VISIB_ATTRIBUTES', 'WDSP_ATTRIBUTES','GUST', 'MAX_ATTRIBUTES', 'MIN_ATTRIBUTES','PRCP_ATTRIBUTES', 'SNDP', 'FRSHTT'], axis = 1)

#pengecekan data
datafiltered

#mengecek data yang kosong
datafiltered.isnull().any()

"""# **PROCESSING**"""

#menentukan variabel independen mempengaruhi
X = datafiltered[['LATITUDE','LONGITUDE', 'ELEVATION', 'WDSP', 'MXSPD', 'MAX', 'MIN','PRCP']] .values  #.astype(float)
X[0:5]

#menentukan variabel dependen dipengaruhi
y = datafiltered['TEMP'].values
y[0:5]

#membagi data menjadi data testing dan data training
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)
print ('Train set:', X_train.shape,  y_train.shape)
print ('Test set:', X_test.shape,  y_test.shape)

#Mengklasifikasikan dan mengimport KNN
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn.fit(X_train, y_train)

#prediksi
yhat = knn.predict(X_test)
yhat [0:50]

#menghitung tingkat akurasi data prediksi
from sklearn import metrics
print("Train set Accuracy: ", metrics.accuracy_score(y_train, knn.predict(X_train)))
print("Test set Accuracy: ", metrics.accuracy_score(y_test, yhat))

#mencari tingkat akurasi terbaik berdasarkan K (Tetangga)
Ks = 10
mean_acc = np.zeros((Ks-1))
std_acc = np.zeros((Ks-1))
ConfustionMx = [];
for n in range(1,Ks):
    
    #Train Model and Predict  
    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)
    yhat=neigh.predict(X_test)
    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)

    
    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])

mean_acc

#menampilkan grafik berdasarkan nilai akurasi K 
plt.plot(range(1,Ks),mean_acc,'g')
plt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)
plt.legend(('Accuracy ', '+/- 3xstd'))
plt.ylabel('Accuracy ')
plt.xlabel('Number of Nabors (K)')
plt.tight_layout()
plt.show()

#mencari akurasi terbaik dengan K keberapa
print( "The best accuracy was with", mean_acc.max(), "with k=", mean_acc.argmax()+1)